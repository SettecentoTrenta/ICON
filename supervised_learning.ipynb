{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a94c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definiamo i nomi delle colonne\n",
    "column_names = [\n",
    "    'id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
    "    'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave_points_mean',\n",
    "    'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se',\n",
    "    'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se',\n",
    "    'concave_points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst',\n",
    "    'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "    'compactness_worst', 'concavity_worst', 'concave_points_worst', 'symmetry_worst',\n",
    "    'fractal_dimension_worst'\n",
    "]\n",
    "\n",
    "data = pd.read_csv('wdbc.data', header=None, names=column_names)\n",
    "\n",
    "data.drop('id', axis=1, inplace=True)\n",
    "le = LabelEncoder()\n",
    "data['diagnosis'] = le.fit_transform(data['diagnosis'])  # 0=B, 1=M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('diagnosis', axis=1)\n",
    "y = data['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_sm = scaler.fit_transform(X_train_sm)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Forma train dopo SMOTE: {X_train_sm.shape}, Classi bilanciate: {np.bincount(y_train_sm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780faaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x=y_train_sm)\n",
    "plt.title('Distribuzione delle Classi nel Training Set dopo SMOTE')\n",
    "plt.xlabel('Diagnosi (0: Benigno, 1: Maligno)')\n",
    "plt.ylabel('Conteggio')\n",
    "plt.xticks([0, 1], ['Benigno (0)', 'Maligno (1)'])\n",
    "\n",
    "# Aggiungi i numeri sopra le barre\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5),\n",
    "                textcoords='offset points')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "counts = np.bincount(y_train_sm)\n",
    "labels = [f'Benigno ({counts[0]})', f'Maligno ({counts[1]})']\n",
    "plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=140, colors=['skyblue', 'lightcoral'])\n",
    "plt.title('Distribuzione a Torta delle Classi nel Training Set dopo SMOTE')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded517ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "n_cols = 5\n",
    "n_rows = 6\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 18))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    ax = axes[i]\n",
    "    ax.hist(X_train_scaled[:, i], bins=30, alpha=0.5,  color='red', density=True, label='Prima')\n",
    "    ax.hist(X_train_sm[:, i], bins=30, alpha=0.25, color='blue',   density=True, label='Dopo SMOTE')\n",
    "    ax.set_title(col, fontsize=9)\n",
    "    ax.tick_params(axis='both', labelsize=8)\n",
    "\n",
    "\n",
    "axes[0].legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('Distribuzione delle features - Prima vs Dopo SMOTE', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb522f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "models = {\n",
    "    'RF': RandomForestClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'GB': GradientBoostingClassifier(random_state=42),\n",
    "    'LR': LogisticRegression(max_iter=100000, random_state=42)\n",
    "}\n",
    "\n",
    "param_dists = {\n",
    "    'RF': {\n",
    "        'n_estimators': [10, 50, 100,],\n",
    "        'max_depth': [10, 15, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [10, 15, 20],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    },\n",
    "    'GB': {\n",
    "        'n_estimators': [10, 50, 100],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [5, 10, 15],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    'LR': [\n",
    "        {\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'solver': ['liblinear']\n",
    "        },\n",
    "        {\n",
    "            'penalty': ['l2'],\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'solver': ['lbfgs']\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"--- {name} ---\")\n",
    "    search = RandomizedSearchCV(\n",
    "        model,\n",
    "        param_distributions=param_dists[name],\n",
    "        n_iter=10,\n",
    "        cv=10,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    search.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "    best_models[name] = search.best_estimator_\n",
    "    print(f\"Migliori parametri: {search.best_params_}\")\n",
    "\n",
    "    # Valutazione sul test set\n",
    "    y_pred_test = best_models[name].predict(X_test)\n",
    "    print(\"\\nReport di classificazione sul test set:\")\n",
    "    print(classification_report(y_test, y_pred_test, target_names=['Benigno (0)', 'Maligno (1)']))\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2235cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics_per_model = {}\n",
    "metrics_to_plot = ['precision', 'recall', 'f1-score']\n",
    "\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, target_names=['Benigno (0)', 'Maligno (1)'])\n",
    "\n",
    "    metrics_per_model[name] = {metric: report['macro avg'][metric] for metric in metrics_to_plot}\n",
    "\n",
    "    metrics_per_model[name]['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "labels = list(metrics_per_model.keys())\n",
    "precision_scores = [metrics_per_model[model]['precision'] for model in labels]\n",
    "recall_scores = [metrics_per_model[model]['recall'] for model in labels]\n",
    "f1_scores = [metrics_per_model[model]['f1-score'] for model in labels]\n",
    "accuracy_scores = [metrics_per_model[model]['accuracy'] for model in labels]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "rects1 = ax.bar(x - 1.5*width, precision_scores, width, label='Precision', color='cornflowerblue')\n",
    "rects2 = ax.bar(x - 0.5*width, recall_scores, width, label='Recall', color='lightcoral')\n",
    "rects3 = ax.bar(x + 0.5*width, f1_scores, width, label='F1-Score', color='lightgreen')\n",
    "rects4 = ax.bar(x + 1.5*width, accuracy_scores, width, label='Accuracy', color='gold')\n",
    "\n",
    "ax.set_ylabel('Punteggio')\n",
    "ax.set_title('Confronto delle Metriche per Modello sul Test Set')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "ax.bar_label(rects1, padding=3, fmt='%.4f')\n",
    "ax.bar_label(rects2, padding=3, fmt='%.4f')\n",
    "ax.bar_label(rects3, padding=3, fmt='%.4f')\n",
    "ax.bar_label(rects4, padding=3, fmt='%.4f')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
