{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a94c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definiamo i nomi delle colonne\n",
    "column_names = [\n",
    "    'id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
    "    'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave_points_mean',\n",
    "    'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se',\n",
    "    'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se',\n",
    "    'concave_points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst',\n",
    "    'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "    'compactness_worst', 'concavity_worst', 'concave_points_worst', 'symmetry_worst',\n",
    "    'fractal_dimension_worst'\n",
    "]\n",
    "\n",
    "data = pd.read_csv('wdbc.data', header=None, names=column_names)\n",
    "\n",
    "data.drop('id', axis=1, inplace=True)\n",
    "le = LabelEncoder()\n",
    "data['diagnosis'] = le.fit_transform(data['diagnosis'])  # 0=B, 1=M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72503342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='diagnosis', data=data)\n",
    "plt.title('Distribuzione delle Classi nel Dataset Originale')\n",
    "plt.xlabel('Diagnosi (0: Benigno, 1: Maligno)')\n",
    "plt.ylabel('Conteggio')\n",
    "plt.xticks([0, 1], ['Benigno (B)', 'Maligno (M)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "counts = data['diagnosis'].value_counts()\n",
    "labels = [f'Benigno ({counts[0]})', f'Maligno ({counts[1]})']\n",
    "plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=140, colors=['skyblue', 'lightcoral'])\n",
    "plt.title('Distribuzione a Torta delle Classi nel Dataset Originale')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('diagnosis', axis=1)\n",
    "y = data['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_sm = scaler.fit_transform(X_train_sm)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Forma train dopo SMOTE: {X_train_sm.shape}, Classi bilanciate: {np.bincount(y_train_sm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780faaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x=y_train_sm)\n",
    "plt.title('Distribuzione delle Classi nel Training Set dopo SMOTE')\n",
    "plt.xlabel('Diagnosi (0: Benigno, 1: Maligno)')\n",
    "plt.ylabel('Conteggio')\n",
    "plt.xticks([0, 1], ['Benigno (0)', 'Maligno (1)'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "counts = np.bincount(y_train_sm)\n",
    "labels = [f'Benigno ({counts[0]})', f'Maligno ({counts[1]})']\n",
    "plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=140, colors=['skyblue', 'lightcoral'])\n",
    "plt.title('Distribuzione a Torta delle Classi nel Training Set dopo SMOTE')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded517ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "n_cols = 5\n",
    "n_rows = 6\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 18))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    ax = axes[i]\n",
    "    ax.hist(X_train_scaled[:, i], bins=30, alpha=0.5,  color='red', density=True, label='Prima')\n",
    "    ax.hist(X_train_sm[:, i], bins=30, alpha=0.25, color='blue',   density=True, label='Dopo SMOTE')\n",
    "    ax.set_title(col, fontsize=9)\n",
    "    ax.tick_params(axis='both', labelsize=8)\n",
    "\n",
    "\n",
    "axes[0].legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('Distribuzione delle features - Prima vs Dopo SMOTE', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb522f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "models = {\n",
    "    'RF': RandomForestClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'GB': GradientBoostingClassifier(random_state=42),\n",
    "    'LR': LogisticRegression(max_iter=100000, random_state=42)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'RF': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [10, 15, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [5, 10, 15, 20],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    },\n",
    "    'GB': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [5, 10, 15],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    'LR': [\n",
    "        {\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'solver': ['liblinear']\n",
    "        },\n",
    "        {\n",
    "            'penalty': ['l2'],\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'solver': ['lbfgs']\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"--- {name} ---\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=10, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    \n",
    "    print(f\"Migliori parametri: {grid.best_params_}\")\n",
    "\n",
    "    # Valutazione sul test set\n",
    "    y_pred_test = best_models[name].predict(X_test)\n",
    "    print(\"\\nReport di classificazione sul test set:\")\n",
    "    print(classification_report(y_test, y_pred_test, target_names=['Benigno (0)', 'Maligno (1)']))\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b451e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "axes = axes.ravel()\n",
    "\n",
    "class_names = ['Benigno', 'Maligno']\n",
    "metrics_to_plot = ['precision', 'recall', 'f1-score']\n",
    "\n",
    "for i, (name, model) in enumerate(best_models.items()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)\n",
    "    \n",
    "    benign_metrics = [report[class_names[0]][m] for m in metrics_to_plot]\n",
    "    malign_metrics = [report[class_names[1]][m] for m in metrics_to_plot]\n",
    "    \n",
    "    accuracy = report['accuracy']\n",
    "    \n",
    "    x = np.arange(len(metrics_to_plot))\n",
    "    width = 0.35\n",
    "\n",
    "    rects1 = ax.bar(x - width/2, benign_metrics, width, label=class_names[0], color='skyblue')\n",
    "    rects2 = ax.bar(x + width/2, malign_metrics, width, label=class_names[1], color='lightcoral')\n",
    "    \n",
    "    ax.axhline(y=accuracy, color='r', linestyle='--', label=f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "    ax.set_ylabel('Punteggio')\n",
    "    ax.set_title(f'Metriche di Valutazione per il modello: {name}')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics_to_plot)\n",
    "    if name == 'GB':\n",
    "        ax.legend(loc='lower left')\n",
    "    else:\n",
    "        ax.legend()\n",
    "    ax.set_ylim(0, 1.1)\n",
    "\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate(f'{height:.2f}',\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d54fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valutazione overfitting (accuracy):\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/usr/lib64/python3.13/multiprocessing/resource_tracker.py\"\u001b[0m, line \u001b[35m295\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    raise ValueError(\n",
      "        f'Cannot register {name} for automatic cleanup: '\n",
      "        f'unknown resource type {rtype}')\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35mCannot register /dev/shm/joblib_memmapping_folder_13861_a2640bc3f1694ce7ba6dadee09d1ea7b_b4a727693dcf499fb6eab52ec274e721 for automatic cleanup: unknown resource type folder\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/usr/lib64/python3.13/multiprocessing/resource_tracker.py\"\u001b[0m, line \u001b[35m295\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    raise ValueError(\n",
      "        f'Cannot register {name} for automatic cleanup: '\n",
      "        f'unknown resource type {rtype}')\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35mCannot register /dev/shm/joblib_memmapping_folder_13861_4e0ae673ddec48deba71bdfb939fb38d_c29c5711a13a4e1fa6783079f2d67ddd for automatic cleanup: unknown resource type folder\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- RF: train=0.996 | CV(mean±std)=0.968±0.021 | test=0.982 | gap=0.014 -> OK\n",
      "- KNN: train=1.000 | CV(mean±std)=0.972±0.021 | test=0.977 | gap=0.023 -> ⚠️ possibile overfitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/usr/lib64/python3.13/multiprocessing/resource_tracker.py\"\u001b[0m, line \u001b[35m295\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    raise ValueError(\n",
      "        f'Cannot register {name} for automatic cleanup: '\n",
      "        f'unknown resource type {rtype}')\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35mCannot register /dev/shm/joblib_memmapping_folder_13861_4e0ae673ddec48deba71bdfb939fb38d_c29c5711a13a4e1fa6783079f2d67ddd for automatic cleanup: unknown resource type folder\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/usr/lib64/python3.13/multiprocessing/resource_tracker.py\"\u001b[0m, line \u001b[35m295\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    raise ValueError(\n",
      "        f'Cannot register {name} for automatic cleanup: '\n",
      "        f'unknown resource type {rtype}')\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35mCannot register /dev/shm/joblib_memmapping_folder_13861_a77f28a174504ef888d7fd302b03a28f_32f029187f74454f84b2310630e03f4e for automatic cleanup: unknown resource type folder\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/usr/lib64/python3.13/multiprocessing/resource_tracker.py\"\u001b[0m, line \u001b[35m295\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    raise ValueError(\n",
      "        f'Cannot register {name} for automatic cleanup: '\n",
      "        f'unknown resource type {rtype}')\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35mCannot register /dev/shm/joblib_memmapping_folder_13861_4e0ae673ddec48deba71bdfb939fb38d_9b81776d6d614a619d1316b872199c5d for automatic cleanup: unknown resource type folder\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/usr/lib64/python3.13/multiprocessing/resource_tracker.py\"\u001b[0m, line \u001b[35m295\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    raise ValueError(\n",
      "        f'Cannot register {name} for automatic cleanup: '\n",
      "        f'unknown resource type {rtype}')\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35mCannot register /dev/shm/joblib_memmapping_folder_13861_4e0ae673ddec48deba71bdfb939fb38d_9b81776d6d614a619d1316b872199c5d for automatic cleanup: unknown resource type folder\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/usr/lib64/python3.13/multiprocessing/resource_tracker.py\"\u001b[0m, line \u001b[35m295\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    raise ValueError(\n",
      "        f'Cannot register {name} for automatic cleanup: '\n",
      "        f'unknown resource type {rtype}')\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35mCannot register /dev/shm/joblib_memmapping_folder_13861_311d30f9f30842e7808273677e894496_04dbfc47a1fa45dba95461d86cdc061d for automatic cleanup: unknown resource type folder\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/usr/lib64/python3.13/multiprocessing/resource_tracker.py\"\u001b[0m, line \u001b[35m295\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    raise ValueError(\n",
      "        f'Cannot register {name} for automatic cleanup: '\n",
      "        f'unknown resource type {rtype}')\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35mCannot register /dev/shm/joblib_memmapping_folder_13861_4e0ae673ddec48deba71bdfb939fb38d_542e211c1314480ea4e8be783340be93 for automatic cleanup: unknown resource type folder\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- GB: train=1.000 | CV(mean±std)=0.974±0.015 | test=0.982 | gap=0.018 -> OK\n",
      "- LR: train=0.990 | CV(mean±std)=0.974±0.010 | test=0.971 | gap=0.019 -> ⚠️ possibile overfitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/usr/lib64/python3.13/multiprocessing/resource_tracker.py\"\u001b[0m, line \u001b[35m295\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    raise ValueError(\n",
      "        f'Cannot register {name} for automatic cleanup: '\n",
      "        f'unknown resource type {rtype}')\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35mCannot register /dev/shm/joblib_memmapping_folder_13861_4e0ae673ddec48deba71bdfb939fb38d_542e211c1314480ea4e8be783340be93 for automatic cleanup: unknown resource type folder\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/usr/lib64/python3.13/multiprocessing/resource_tracker.py\"\u001b[0m, line \u001b[35m295\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    raise ValueError(\n",
      "        f'Cannot register {name} for automatic cleanup: '\n",
      "        f'unknown resource type {rtype}')\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35mCannot register /dev/shm/joblib_memmapping_folder_13861_2d171e3d7eaf4c3ebf04c969f80f1cc3_9280bcd357f4496691bb489e644f4a1b for automatic cleanup: unknown resource type folder\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/usr/lib64/python3.13/multiprocessing/resource_tracker.py\"\u001b[0m, line \u001b[35m295\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    raise ValueError(\n",
      "        f'Cannot register {name} for automatic cleanup: '\n",
      "        f'unknown resource type {rtype}')\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35mCannot register /dev/shm/joblib_memmapping_folder_13861_4e0ae673ddec48deba71bdfb939fb38d_5b9c7e894677418b8c60b4363aa24056 for automatic cleanup: unknown resource type folder\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/usr/lib64/python3.13/multiprocessing/resource_tracker.py\"\u001b[0m, line \u001b[35m295\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "    raise ValueError(\n",
      "        f'Cannot register {name} for automatic cleanup: '\n",
      "        f'unknown resource type {rtype}')\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35mCannot register /dev/shm/joblib_memmapping_folder_13861_4e0ae673ddec48deba71bdfb939fb38d_5b9c7e894677418b8c60b4363aa24056 for automatic cleanup: unknown resource type folder\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Verifica overfitting: confronto accuracy train vs test e CV a 5 fold\n",
    "\n",
    "soglia_gap = 0.019  # soglia indicativa per gap train-test\n",
    "print(\"Valutazione overfitting (accuracy):\\n\")\n",
    "\n",
    "risultati_overfit = {}\n",
    "for name, model in best_models.items():\n",
    "    train_acc = model.score(X_train_sm, y_train_sm)\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    cv_scores = cross_val_score(model, X_train_sm, y_train_sm, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "    cv_mean, cv_std = cv_scores.mean(), cv_scores.std()\n",
    "    gap = train_acc - test_acc\n",
    "\n",
    "    risultati_overfit[name] = {\n",
    "        'train_acc': train_acc,\n",
    "        'cv_mean': cv_mean,\n",
    "        'cv_std': cv_std,\n",
    "        'test_acc': test_acc,\n",
    "        'gap_train_test': gap\n",
    "    }\n",
    "\n",
    "    flag = \"⚠️ possibile overfitting\" if (gap > soglia_gap and train_acc > cv_mean and train_acc > test_acc) else \"OK\"\n",
    "    print(f\"- {name}: train={train_acc:.3f} | CV(mean±std)={cv_mean:.3f}±{cv_std:.3f} | test={test_acc:.3f} | gap={gap:.3f} -> {flag}\")\n",
    "\n",
    "# Nota: per una stima più corretta con SMOTE, eseguire SMOTE all'interno della CV tramite una Pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
