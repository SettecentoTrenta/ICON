{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb8503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Definiamo i nomi delle colonne\n",
    "column_names = [\n",
    "    'id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
    "    'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave_points_mean',\n",
    "    'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se',\n",
    "    'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se',\n",
    "    'concave_points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst',\n",
    "    'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "    'compactness_worst', 'concavity_worst', 'concave_points_worst', 'symmetry_worst',\n",
    "    'fractal_dimension_worst'\n",
    "]\n",
    "\n",
    "data = pd.read_csv('wdbc.data', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separiamo le features dal target\n",
    "X = data.drop(columns=['id', 'diagnosis'])\n",
    "y = data['diagnosis']\n",
    "\n",
    "# Applichiamo SMOTE per bilanciare il dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Creiamo un nuovo DataFrame bilanciato\n",
    "data_resampled = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='diagnosis')], axis=1)\n",
    "\n",
    "print(\"Distribuzione delle classi prima di SMOTE:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nDistribuzione delle classi dopo SMOTE:\")\n",
    "print(y_resampled.value_counts())\n",
    "\n",
    "# Sovrascriviamo il DataFrame originale con quello bilanciato per le celle successive\n",
    "data = data_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5db53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import HillClimbSearch, K2Score\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.inference import VariableElimination\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "features = data.drop(columns=['diagnosis'])\n",
    "target = data['diagnosis']\n",
    "\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform', subsample=None)\n",
    "features_disc = pd.DataFrame(discretizer.fit_transform(features), columns=features.columns, index=data.index).astype(int)\n",
    "\n",
    "data_disc = pd.concat([features_disc, target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7030218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_method = K2Score(data_disc)\n",
    "hc = HillClimbSearch(data_disc)\n",
    "best_model = hc.estimate(scoring_method=scoring_method, max_indegree=5, max_iter=int(1e4))\n",
    "print(\"Archi appresi:\", best_model.edges())\n",
    "\n",
    "bn = BayesianNetwork(best_model.edges())\n",
    "bn.fit(data_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b027591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(40, 40))\n",
    "\n",
    "G = nx.DiGraph(best_model.edges())\n",
    "\n",
    "node_colors = ['red' if node == 'diagnosis' else 'skyblue' for node in G.nodes()]\n",
    "\n",
    "pos = nx.spring_layout(G, k=2.5, iterations=150)\n",
    "nx.draw(G, pos, with_labels=True, node_size=5000, node_color=node_colors, font_size=25, font_weight='bold', arrows=True, arrowsize=23)\n",
    "plt.title(\"Struttura della Rete Bayesiana Appresa\", size=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f54553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_blanket = bn.get_markov_blanket('diagnosis')\n",
    "\n",
    "print(f\"La Markov Blanket di 'diagnosis' Ã¨: {markov_blanket}\")\n",
    "print(f\"\\nNumero di features nella Markov Blanket: {len(markov_blanket)}\")\n",
    "print(f\"\\nSono state eliminate {32 - len(markov_blanket)} features.\")\n",
    "print(\"\\nQueste sono le uniche variabili necessarie per predire la diagnosi secondo il modello appreso.\")\n",
    "print(\"Le altre variabili possono essere considerate ridondanti per questo scopo.\")\n",
    "\n",
    "features_ridotte = markov_blanket.copy()\n",
    "if 'diagnosis' not in features_ridotte:\n",
    "    features_ridotte.append('diagnosis')\n",
    "\n",
    "data_ridotto = data[features_ridotte]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6323d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ridotto = G.subgraph(features_ridotte)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "node_colors_ridotto = ['red' if node == 'diagnosis' else 'skyblue' for node in G_ridotto.nodes()]\n",
    "\n",
    "pos_ridotto = nx.spring_layout(G_ridotto, k=3.5, iterations=150)\n",
    "nx.draw(G_ridotto, pos_ridotto, with_labels=True, node_size=6000, node_color=node_colors_ridotto, font_size=20, font_weight='bold', arrows=True, arrowsize=20)\n",
    "plt.title(\"Sottografo della Rete Bayesiana: (Markov Blanket)\", size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "X_ridotto = data_ridotto.drop('diagnosis', axis=1)\n",
    "y_ridotto_str = data_ridotto['diagnosis']\n",
    "\n",
    "X_ridotto_disc = pd.DataFrame(discretizer.fit_transform(X_ridotto), columns=X_ridotto.columns, index=X_ridotto.index).astype(int)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_ridotto = pd.Series(le.fit_transform(y_ridotto_str), name='diagnosis', index=y_ridotto_str.index)\n",
    "\n",
    "data_ridotto_disc = pd.concat([X_ridotto_disc, y_ridotto], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_ridotto_disc, y_ridotto, test_size=0.3, random_state=42, stratify=y_ridotto\n",
    ")\n",
    "\n",
    "bn_ridotto = BayesianNetwork(G_ridotto.edges())\n",
    "bn_ridotto.fit(pd.concat([X_train, y_train], axis=1))\n",
    "\n",
    "inference = VariableElimination(bn_ridotto)\n",
    "y_pred = []\n",
    "\n",
    "X_test_for_pred = X_test.copy()\n",
    "\n",
    "for index, row in X_test_for_pred.iterrows():\n",
    "    pred = inference.map_query(variables=['diagnosis'], evidence=row.to_dict())\n",
    "    y_pred.append(pred['diagnosis'])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=le.classes_, output_dict=True)\n",
    "report_str = classification_report(y_test, y_pred, target_names=le.classes_)\n",
    "\n",
    "print(f\"Accuracy del modello ridotto: {accuracy:.4f}\\n\")\n",
    "print(\"Report di Classificazione del Modello Ridotto:\\n\")\n",
    "print(report_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0b0821",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = bn_ridotto.simulate(n_samples=400, seed=42)\n",
    "diagnosis_counts = random_samples['diagnosis'].value_counts()\n",
    "print(\"Numero di campioni generati per ciascuna diagnosi:\\n\", diagnosis_counts)\n",
    "print(random_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ordiniamo i conteggi per indice per garantire che le etichette corrispondano (B, M)\n",
    "ordered_counts = diagnosis_counts.sort_index()\n",
    "\n",
    "# Otteniamo le etichette delle classi ('B', 'M') dal LabelEncoder\n",
    "class_labels = le.inverse_transform(ordered_counts.index)\n",
    "\n",
    "# Creiamo il grafico a barre\n",
    "plt.figure(figsize=(8, 6))\n",
    "barplot = sns.barplot(x=class_labels, y=ordered_counts.values, palette=\"viridis\")\n",
    "\n",
    "# Aggiungiamo titolo ed etichette agli assi\n",
    "plt.title(\"Distribuzione dei Campioni Sintetici Generati\", fontsize=16)\n",
    "plt.xlabel(\"Diagnosi\", fontsize=12)\n",
    "plt.ylabel(\"Numero di Campioni\", fontsize=12)\n",
    "\n",
    "# Aggiungiamo i valori sopra le barre\n",
    "for i in barplot.containers:\n",
    "    barplot.bar_label(i,)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Creiamo il grafico a torta per mostrare le percentuali\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(ordered_counts.values, labels=class_labels, autopct='%1.1f%%', startangle=140, colors=['lightcoral', 'lightskyblue'])\n",
    "plt.title(\"Percentuale dei Campioni Sintetici per Diagnosi\", fontsize=16)\n",
    "plt.axis('equal')  # Assicura che il grafico a torta sia disegnato come un cerchio.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c01aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Estraiamo le medie delle metriche dal report\n",
    "avg_precision = report['macro avg']['precision']\n",
    "avg_recall = report['macro avg']['recall']\n",
    "avg_f1 = report['macro avg']['f1-score']\n",
    "\n",
    "metric_labels = ['Precision', 'Recall', 'F1-Score']\n",
    "metric_values = [avg_precision, avg_recall, avg_f1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "bars = ax.bar(metric_labels, metric_values, color=['skyblue', 'lightgreen', 'salmon'])\n",
    "\n",
    "ax.set_ylabel('Punteggio')\n",
    "ax.set_title('Metriche Medie di Valutazione del Modello Ridotto')\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "# Aggiungiamo la linea dell'accuracy per confronto\n",
    "ax.axhline(y=accuracy, color='r', linestyle='--', label=f'Accuracy: {accuracy:.3f}')\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(bars, padding=3, fmt='%.3f')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
